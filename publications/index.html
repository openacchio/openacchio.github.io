<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Olivier Penacchio</title> <meta name="author" content="Olivier Penacchio"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon_webpage_small.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://openacchio.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Olivier </span>Penacchio</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <div class="publications"> <h2 class="year">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="tbd" class="col-sm-8"> <div class="title">Meta-learning in active inference, Commentary on Binz et al. (2023)</div> <div class="author"> <em>Olivier Penacchio</em>, and <a href="https://brainvitge.org/member/ana-clemente-sanchez/" rel="external nofollow noopener" target="_blank">Ana Clemente</a> </div> <div class="periodical"> <em>Behavioral and Brain Sciences</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">tbd</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Penacchio, Olivier and Clemente, Ana}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Meta-learning in active inference, Commentary on Binz et al. (2023)}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Behavioral and Brain Sciences}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/cover_proposal_Penacchio_et_al_MEE-23-05-306.R2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/cover_proposal_Penacchio_et_al_MEE-23-05-306.R2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/cover_proposal_Penacchio_et_al_MEE-23-05-306.R2-1400.webp"></source> <img src="/assets/img/publication_preview/cover_proposal_Penacchio_et_al_MEE-23-05-306.R2.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="cover_proposal_Penacchio_et_al_MEE-23-05-306.R2.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="WOS:001121340900001" class="col-sm-8"> <div class="title">A computational neuroscience framework for quantifying warning signals</div> <div class="author"> O. Penacchio, C. G. Halpin, I. C. Cuthill, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'P. G. Lovell, M. Wheelwright, J. Skelhorn, C. Rowe, J. M. Harris' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>Methods in Ecology and Evolution</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.14268" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://besjournals.onlinelibrary.wiley.com/doi/pdfdirect/10.1111/2041-210X.14268" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://besjournals.onlinelibrary.wiley.com/action/downloadSupplement?doi=10.1111%2F2041-210X.14268&amp;file=mee314268-sup-0001-Supinfo.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Supp</a> <a href="https://doi.org/10.5061/dryad.x3ffbg7kd" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1111/2041-210X.14268" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1111/2041-210X.14268" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Animal warning signals show remarkable diversity, yet subjectively appear to share certain visual features that make defended prey stand out and look different from more cryptic palatable species. For example, many (but far from all) warning signals involve high contrast elements, such as stripes and spots, and often involve the colours yellow and red. How exactly do aposematic species differ from non-aposematic ones in the eyes (and brains) of their predators? Here, we develop a novel computational modelling approach, to quantify prey warning signals and establish what visual features they share. First, we develop a model visual system, made of artificial neurons with realistic receptive fields, to provide a quantitative estimate of the neural activity in the first stages of the visual system of a predator in response to a pattern. The system can be tailored to specific species. Second, we build a novel model that defines a ‘neural signature’, comprising quantitative metrics that measure the strength of stimulation of the population of neurons in response to patterns. This framework allows us to test how individual patterns stimulate the model predator visual system. For the predator-prey system of birds foraging on lepidopteran prey, we compared the strength of stimulation of a modelled avian visual system in response to a novel database of hyperspectral images of aposematic and undefended butterflies and moths. Warning signals generate significantly stronger activity in the model visual system, setting them apart from the patterns of undefended species. The activity was also very different from that seen in response to natural scenes. Therefore, to their predators, lepidopteran warning patterns are distinct from their non-defended counterparts and stand out against a range of natural backgrounds. For the first time, we present an objective and quantitative definition of warning signals based on how the pattern generates population activity in a neural model of the brain of the receiver. This opens new perspectives for understanding and testing how warning signals have evolved, and, more generally, how sensory systems constrain signal design.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WOS:001121340900001</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Penacchio, O. and Halpin, C. G. and Cuthill, I. C. and Lovell, P. G. and Wheelwright, M. and Skelhorn, J. and Rowe, C. and Harris, J. M.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A computational neuroscience framework for quantifying warning signals}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Methods in Ecology and Evolution}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{103-116}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1111/2041-210X.14268}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2041-210X}</span><span class="p">,</span>
  <span class="na">eissn</span> <span class="p">=</span> <span class="s">{2041-2096}</span><span class="p">,</span>
  <span class="na">osf</span> <span class="p">=</span> <span class="s">{https://doi.org/10.5061/dryad.x3ffbg7kd}</span><span class="p">,</span>
  <span class="na">database</span> <span class="p">=</span> <span class="s">{https://arts.st-andrews.ac.uk/lepidoptera/}</span><span class="p">,</span>
  <span class="na">orcid-numbers</span> <span class="p">=</span> <span class="s">{Cuthill, Innes/0000-0002-5007-8856
     Harris, Julie/0000-0002-3497-4503
     Skelhorn, John/0000-0002-8385-4831
     Lovell, Paul George/0000-0003-2959-5370
     Rowe, Candy/0000-0001-5379-843X}</span><span class="p">,</span>
  <span class="na">unique-id</span> <span class="p">=</span> <span class="s">{WOS:001121340900001}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Frontiers%20in%20Neuroscience%202023-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Frontiers%20in%20Neuroscience%202023-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Frontiers%20in%20Neuroscience%202023-1400.webp"></source> <img src="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Frontiers%20in%20Neuroscience%202023.jpg" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration Penacchio et al Frontiers in Neuroscience 2023.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="WOS:001041614900001" class="col-sm-8"> <div class="title">A mechanistic account of visual discomfort</div> <div class="author"> <em>Olivier Penacchio</em>, Xavier Otazu, Arnold J. Wilkins, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Sarah M. Haigh' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Frontiers in Neuroscience</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2023.1200661/full" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/A%20mechanistic%20account%20of%20visual%20discomfort%20Penacchio%20et%20al%202023%20revised%20version%20accepted.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/Supplementary%20Material%20A%20mechanistic%20account%20of%20visual%20discomfort%20Penacchio%20et%20al%202023%20revised%20version%20accepted.pdf" class="btn btn-sm z-depth-0" role="button">Supp</a> <a href="https://doi.org/10.5061/dryad.g79cnp5kw" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="tbd" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="tbd" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Much of the neural machinery of the early visual cortex, from the extraction of local orientations to contextual modulations through lateral interactions, is thought to have developed to provide a sparse encoding of contour in natural scenes, allowing the brain to process efficiently most of the visual scenes we are exposed to. Certain visual stimuli, however, cause visual stress, a set of adverse effects ranging from simple discomfort to migraine attacks, and epileptic seizures in the extreme, all phenomena linked with an excessive metabolic demand. The theory of efficient coding suggests a link between excessive metabolic demand and images that deviate from natural statistics. Yet, the mechanisms linking energy demand and image spatial content in discomfort remain elusive. Here, we used theories of visual coding that link image spatial structure and brain activation to characterize the response to images observers reported as uncomfortable in a biologically based neurodynamic model of the early visual cortex that included excitatory and inhibitory layers to implement contextual influences. We found three clear markers of aversive images: a larger overall activation in the model, a less sparse response, and a more unbalanced distribution of activity across spatial orientations. When the ratio of excitation over inhibition was increased in the model, a phenomenon hypothesised to underlie interindividual differences in susceptibility to visual discomfort, the three markers of discomfort progressively shifted towards values typical of the response to uncomfortable stimuli. Overall, these findings propose a unifying mechanistic explanation for why there are differences between images and between observers, suggesting how visual input and idiosyncratic hyperexcitability give rise to abnormal brain responses that result in visual stress.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WOS:001041614900001</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Penacchio, Olivier and Otazu, Xavier and Wilkins, Arnold J. and Haigh, Sarah M.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A mechanistic account of visual discomfort}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Neuroscience}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{tbd}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{tbd}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{tbd}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{tbd}</span><span class="p">,</span>
  <span class="na">data</span> <span class="p">=</span> <span class="s">{https://doi.org/10.5061/dryad.g79cnp5kw}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration%20Kikuchi%20et%20al%20J%20of%20Evolutionary%20Biology%202023.JPG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration%20Kikuchi%20et%20al%20J%20of%20Evolutionary%20Biology%202023.JPG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration%20Kikuchi%20et%20al%20J%20of%20Evolutionary%20Biology%202023.JPG-1400.webp"></source> <img src="/assets/img/publication_preview/illustration%20Kikuchi%20et%20al%20J%20of%20Evolutionary%20Biology%202023.JPG" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration Kikuchi et al J of Evolutionary Biology 2023.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="WOS:001023571300001" class="col-sm-8"> <div class="title">The evolution and ecology of multiple antipredator defences</div> <div class="author"> D.W. Kikuchi, W.L. Allen, K. Arbuckle, and <span class="more-authors" title="click to view 43 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '43 more authors' ? 'T.G. Aubier, E.S. Briolat, E.R. Burdfield-Steel, K.L. Cheney, K. Daňková, M. Elias, L. Hämäläinen, M.E. Herberstein, T.J. Hossie, M. Joron, K. Kunte, B.C. Leavell, C. Lindstedt, U. Lorioux Chevalier, M. McClure, C.F. McLellan, I. Medina, V. Nawge, E. Páez, A. Pal, S. Pekár, Olivier Penacchio, J. Raška, T. Reader, Rojas B., K.H. Rönkä, D.C. Rößler, C. Rowe, H.M. Rowland, A. Roy, K.A. Schaal, T.N. Sherratt, J. Skelhorn, H.R. Smart, T. Stankowich, A.M. Stefan, K. Summers, C.H. Taylor, R. Thorogood, K. Umbers, A.E. Winters, J. Yeager, A. Exnerová' : '43 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">43 more authors</span> </div> <div class="periodical"> <em>Journal of Evolutionary Biology</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://onlinelibrary.wiley.com/doi/10.1111/jeb.14192" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/J%20of%20Evolutionary%20Biology%20-%202023%20-%20Kikuchi%20-%20The%20evolution%20and%20ecology%20of%20multiple%20antipredator%20defences.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="0.1111/jeb.14192" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="0.1111/jeb.14192" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Prey seldom rely on a single type of antipredator defence, often using multiple defences to avoid predation. In many cases, selection in different contexts may favour the evolution of multiple defences in a prey. However, a prey may use multiple defences to protect itself during a single predator encounter. Such “defence portfolios” that defend prey against a single instance of predation are distributed across and within successive stages of the predation sequence (encounter, detection, identification, approach (attack), subjugation and consumption). We contend that at present, our understanding of defence portfolio evolution is incomplete, and seen from the fragmentary perspective of specific sensory systems (e.g., visual) or specific types of defences (especially aposematism). In this review, we aim to build a comprehensive framework for conceptualizing the evolution of multiple prey defences, beginning with hypotheses for the evolution of multiple defences in general, and defence portfolios in particular. We then examine idealized models of resource trade-offs and functional interactions between traits, along with evidence supporting them. We find that defence portfolios are constrained by resource allocation to other aspects of life history, as well as functional incompatibilities between different defences. We also find that selection is likely to favour combinations of defences that have synergistic effects on predator behaviour and prey survival. Next, we examine specific aspects of prey ecology, genetics and development, and predator cognition that modify the predictions of current hypotheses or introduce competing hypotheses. We outline schema for gathering data on the distribution of prey defences across species and geography, determining how multiple defences are produced, and testing the proximate mechanisms by which multiple prey defences impact predator behaviour. Adopting these approaches will strengthen our understanding of multiple defensive strategies.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/animation_Yeager_Penacchio_ProcRoySocB_2023.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/animation_Yeager_Penacchio_ProcRoySocB_2023.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/animation_Yeager_Penacchio_ProcRoySocB_2023.gif-1400.webp"></source> <img src="/assets/img/publication_preview/animation_Yeager_Penacchio_ProcRoySocB_2023.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="animation_Yeager_Penacchio_ProcRoySocB_2023.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.1098/rspb.2023.0327" class="col-sm-8"> <div class="title">Outcomes of multifarious selection on the evolution of visual signals</div> <div class="author"> <a href="http://www.justinyeager.org/" rel="external nofollow noopener" target="_blank">Justin Yeager*</a>, and <em>Olivier Penacchio*</em> </div> <div class="periodical"> <em>Proceedings of the Royal Society B</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://royalsocietypublishing.org/doi/full/10.1098/rspb.2023.0327" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Outcomes%20of%20multifarious%20selection%20on%20the%20evolution%20of%20visual%20signals%20Yeager%20Penacchio%20Proc%20Roy%20Soc%20B%202023%20accepted%20version.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1098/rspb.2023.0327" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1098/rspb.2023.0327" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Multifarious sources of selection shape visual signals and can produce phenotypic divergence. Theory predicts that variance in warning signals should be minimal due to purifying selection, yet polymorphism is abundant. While in some instances divergent signals can evolve into discrete morphs, continuously variable phenotypes are also encountered in natural populations. Notwithstanding, we currently have an incomplete understanding of how combinations of selection shape fitness landscapes, particularly those which produce polymorphism. We modeled how combinations of natural and sexual selection act on aposematic traits within a single population to gain insights into what combinations of selection favors the evolution and maintenance of phenotypic variation. With a rich foundation of studies on selection and phenotypic divergence, we reference the poison frog genus Oophaga to model signal evolution. Multifarious selection on aposematic traits created the topology of our model’s fitness landscape by approximating different scenarios found in natural populations. Combined, the model produced all types of phenotypic variation found in frog populations, namely monomorphism, continuous variation, and discrete polymorphism. Our results afford advances into how multifarious selection shapes phenotypic divergence, which, along with additional modelling enhancements, will allow us to further our understanding of visual signal evolution.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration%20Clemente%20et%20al%20PsychoCreatArt%202023.JPG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration%20Clemente%20et%20al%20PsychoCreatArt%202023.JPG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration%20Clemente%20et%20al%20PsychoCreatArt%202023.JPG-1400.webp"></source> <img src="/assets/img/publication_preview/illustration%20Clemente%20et%20al%20PsychoCreatArt%202023.JPG" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration Clemente et al PsychoCreatArt 2023.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.3389/fnins.2021.711064" class="col-sm-8"> <div class="title">Explaining the curvature effect: Perceptual and hedonic evaluations of visual contour</div> <div class="author"> <a href="https://brainvitge.org/member/ana-clemente-sanchez/" rel="external nofollow noopener" target="_blank">Ana Clemente</a>, <em>Olivier Penacchio</em>, Manel Vila-Vidal, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Robert Pepperell, Nicole Ruta' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Psychology of Aesthetics, Creativity, and the Arts</em>, 2023 </div> <div class="periodical"> (In Press.) </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2Faca0000561" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Explaining%20the%20curvature%20effect_Clemente_et_al_2023_preprint_version.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1037/aca0000561" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1037/aca0000561" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Preference for curvature, the curvature effect, seems to transcend cultures, species and stimulus kinds. However, its nature and psychological mechanisms remain obscure because studies often overlook the complexity of contour characterisation and disregard personal and contextual factors. To investigate the curvature effect, we propose a continuous and multidimensional manipulation and contrasting experimental conditions examined at the group and individual levels that unveil a complex picture, not reducible to monotonous relationships: Perceptual and hedonic evaluations relied on multiple geometric features defining contour and shape. These features were specifically weighted to characterise each construct, depending on the individual and contingent on whether evaluating perceptually or hedonically. Crucially, the curvature effect was not robust to preference with respect to the median and continuous manipulations of contour for varying shapes. As curved contours are more easily perceived and processed than polygons, we hypothesised that perceived contour might explain liking for a figure beyond the effect of geometric features, finding that this association was subordinated to shape categorisations. Finally, domain-specific, personality and cognitive-preference traits moderated how people used each geometric feature in their perceptual and hedonic evaluations. We conclude that research on perception and appreciation of contour and shape should factor in their complexity and defining features. Additionally, embracing individual sensitivities opens potential avenues to advance the understanding of psychological phenomena. In summary, our approach unpacks a complex picture of contour preference that prompts critical reflections on past research and advice for future research, and it is applicable to other psychological constructs.</p> </div> </div> </div> </li> </ol> <h2 class="year">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"></div> <div id="10.3389/fnins.2021.711065" class="col-sm-8"> <div class="title">Visual stress responses to static images are associated with symptoms of Persistent Postural Perceptual Dizziness (PPPD)</div> <div class="author"> Georgina Powell, <em>Olivier Penacchio</em>, Hannah Derry-Sumner, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Simon K. Rushton, Deepak Rajenderkumar, Petroc Sumner' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Journal of Vestibular Research</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://content.iospress.com/articles/journal-of-vestibular-research/ves190578" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.3233/VES-190578" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.3233/VES-190578" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>BACKGROUND: Images that deviate from natural scene statistics in terms of spatial frequency and orientation content can produce visual stress (also known as visual discomfort), especially for migraine sufferers. These images appear to over-activate the visual cortex. OBJECTIVE: To connect the literature on visual discomfort with a common chronic condition presenting in neuro-otology clinics known as persistent postural perceptual dizziness (PPPD). Patients experience dizziness when walking through highly cluttered environments or when watching moving stimuli. This is thought to arise from maladaptive interaction between vestibular and visual signals for balance. METHODS: We measured visual discomfort to stationary images in patients with PPPD (N = 30) and symptoms of PPPD in a large general population cohort (N = 1858) using the VisualVertigo Analogue Scale(VVAS) and the Situational Characteristics Questionnaire (SCQ). RESULTS: We found that patients with PPPD, and individuals in the general population with more PPPD symptoms, report heightened visual discomfort to stationary images that deviate from natural spectra (patient comparison, F (1, 1865) = 29, p &lt; 0.001; general population correlations, VVAS, r(s) (1387) = 0.46, p &lt; 0.001; SCQ, r(s) (1387) = 0.39, p &lt; 0.001). These findings were not explained by co-morbid migraine. Indeed, PPPD symptoms showed a significantly stronger relationship with visual discomfort than did migraine (VVAS, z(H) = 8.81, p &lt; 0.001; SCQ, z(H) = 6.29, p &lt; 0.001). CONCLUSIONS: We speculate that atypical visual processing - perhaps due to a visual cortex more prone to over-activation - may predispose individuals to PPPD, possibly helping to explain why some patients with vestibular conditions develop PPPD and some do not.</p> </div> </div> </div> </li></ol> <h2 class="year">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Frontiers%20in%20Neuroscience%202021.JPG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Frontiers%20in%20Neuroscience%202021.JPG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Frontiers%20in%20Neuroscience%202021.JPG-1400.webp"></source> <img src="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Frontiers%20in%20Neuroscience%202021.JPG" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration Penacchio et al Frontiers in Neuroscience 2021.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10.3389/fnins.2021.711066" class="col-sm-8"> <div class="title">Visual Discomfort and Variations in Chromaticity in Art and Nature</div> <div class="author"> <em>Olivier Penacchio</em>, Sarah M. Haigh, Xortia Ross, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Rebecca Ferguson, Arnold J. Wilkins' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Frontiers in Neuroscience</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.frontiersin.org/articles/10.3389/fnins.2021.711064/full" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Visual%20Discomfort%20and%20Variations%20in%20Chromaticity%20Frontiers%20in%20Neuroscience%20Penacchio%20et%20al%202021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="/assets/pdf/Suppl%20Mat%20Visual%20Discomfort%20and%20Variations%20in%20Chromaticity%20Frontiers%20in%20Neuroscience%20Penacchio%20et%20al%202021.pdf" class="btn btn-sm z-depth-0" role="button">Supp</a> <a href="https://github.com/openacchio/polymorphism-scenarios-and-free-energy-solver" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.3389/fnins.2021.711064" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.3389/fnins.2021.711064" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Visual discomfort is related to the statistical regularity of visual images. The contribution of luminance contrast to visual discomfort is well understood and can be framed in terms of a theory of efficient coding of natural stimuli, and linked to metabolic demand. While color is important in our interaction with nature, the effect of color on visual discomfort has received less attention. In this study, we build on the established association between visual discomfort and differences in chromaticity across space. We average the local differences in chromaticity in an image and show that this average is a good predictor of visual discomfort from the image. It accounts for part of the variance left unexplained by variations in luminance. We show that the local chromaticity difference in uncomfortable stimuli is high compared to that typical in natural scenes, except in particular infrequent conditions such as the arrangement of colorful fruits against foliage. Overall, our study discloses a new link between visual ecology and discomfort whereby discomfort arises when adaptive perceptual mechanisms are overstimulated by specific classes of stimuli rarely found in nature.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.3389/fnins.2021.711066</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Penacchio, Olivier and Haigh, Sarah M. and Ross, Xortia and Ferguson, Rebecca and Wilkins, Arnold J.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Visual Discomfort and Variations in Chromaticity in Art and Nature}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Neuroscience}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3389/fnins.2021.711064}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1662-453X}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.3389/fnins.2021.711064}</span><span class="p">,</span>
  <span class="na">data</span> <span class="p">=</span> <span class="s">{https://github.com/openacchio/polymorphism-scenarios-and-free-energy-solver}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration_Brinciotti_EB_2021.JPG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration_Brinciotti_EB_2021.JPG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration_Brinciotti_EB_2021.JPG-1400.webp"></source> <img src="/assets/img/publication_preview/illustration_Brinciotti_EB_2021.JPG" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration_Brinciotti_EB_2021.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="WOS:000693182100053" class="col-sm-8"> <div class="title">Pattern-sensitive patients with epilepsy use uncomfortable visual stimuli to self-induce seizures</div> <div class="author"> Mario Brinciotti, Arnold J. Wilkins, <em>Olivier Penacchio</em>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Maria Matricardi' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Epilepsy &amp; Behavior</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.epilepsybehavior.com/article/S1525-5050(21)00450-9/fulltext" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Brinciotti%20et%20al.%20EB%202021%20accepted%20version.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1016/j.yebeh.2021.108189" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1016/j.yebeh.2021.108189" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Sensory stimuli can induce seizures in patients with epilepsy and predisposed subjects. Visual stimuli are the most common triggers, provoking seizures through an abnormal response to light or pattern. Sensitive patients may intentionally provoke their seizures through visual stimuli. Self-induction methods are widely described in photo-sensitive patients, while there are only a few reports of those who are pattern-sensitive. We analyzed 73 images of environmental visual triggers collected from 14 pattern-sensitive patients with self-induced seizures. The images were categorized according to their topics: 29 Objects (43%); 19 Patterns (28%); 15 External scenes (22%); 4 TV or computer screens (6%). Six photos were of poor quality and were excluded from analysis. Images were analyzed by an algorithm that calculated the degree to which the Fourier amplitude spectrum differed from that in images from nature. The algorithm has been shown to predict discomfort in healthy observers. The algorithm identified thirty-one images (46%) as “uncomfortable”. There were significant differences between groups of images (ANOVA p =.0036; Chi2 p &lt; .0279), with higher values of difference from nature in the images classified as “Objects” (mean 6,81E+11; SD 6,72E+11; n.17, 59%) and “Pattern” (mean 9,05E+11; SD 6,86E+11; n.14, 74%). During the semi-structured face-to-face interviews, all patients described the visual triggers as ‘uncomfortable’; the appearance of enjoyable visual epileptic symptoms (especially multi-colored hallucinations) transformed uncomfortable images into pleasant stimuli. Patients considered self-induction as the simplest and most effective way to overcome stressful situations, suggesting that self-inducing pattern sensitive patients often use uncomfortable visual stimuli to trigger their seizures. Among the reasons for the self-inducing behavior, the accidental discovery of pleasurable epileptic symptoms related to these “uncomfortable” visual stimuli should be considered. (c) 2021 Elsevier Inc. All rights reserved.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WOS:000693182100053</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Brinciotti, Mario and Wilkins, Arnold J. and Penacchio, Olivier and Matricardi, Maria}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Pattern-sensitive patients with epilepsy use uncomfortable visual
     stimuli to self-induce seizures}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Epilepsy \&amp; Behavior}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{122}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.yebeh.2021.108189}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1525-5050}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.yebeh.2021.108189}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration_Mavrovouna%20Biol.J.Linn.Soc.%202021.JPG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration_Mavrovouna%20Biol.J.Linn.Soc.%202021.JPG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration_Mavrovouna%20Biol.J.Linn.Soc.%202021.JPG-1400.webp"></source> <img src="/assets/img/publication_preview/illustration_Mavrovouna%20Biol.J.Linn.Soc.%202021.JPG" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration_Mavrovouna Biol.J.Linn.Soc. 2021.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="WOS:000728145600002" class="col-sm-8"> <div class="title">Orienting to the sun improves camouflage for bilaterally symmetrical prey</div> <div class="author"> Veronica Mavrovouna, <em>Olivier Penacchio</em>, and William L. Allen</div> <div class="periodical"> <em>Biological Journal of the Linnean Society</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://academic.oup.com/biolinnean/article/134/4/803/6373266?login=true" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Orienting%20to%20the%20sun%20Mavronouva%20Penacchio%20Allen%20Biological%20Journal%20of%20the%20Linnean%20Society%202021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1093/biolinnean/blab130" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1093/biolinnean/blab130" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Here, we investigate the camouflage consequences of animal orientation behaviour. Shadows can be a conspicuous cue to the presence of prey. For bilaterally symmetrical animals, light field modelling indicates that camouflage will be improved when an animal orients its longitudinal axis directly towards or away from the sun, because the appearance of shadows is minimized. We test this prediction with a field predation experiment, in which wild birds hunt for artificial camouflaged prey oriented with the longitudinal axis either parallel or perpendicular to the sun. We find that prey oriented parallel to the sun are 3.93 times more likely to survive than prey oriented perpendicular to the sun. This result demonstrates the strong orientation dependence of camouflage. Given the dramatic difference in survival of prey with different orientations, we suggest that camouflage should be investigated as an important determinant of the positional behaviour of animals.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WOS:000728145600002</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mavrovouna, Veronica and Penacchio, Olivier and Allen, William L.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Orienting to the sun improves camouflage for bilaterally symmetrical
     prey}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Biological Journal of the Linnean Society}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{134}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{803-808}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1093/biolinnean/blab130}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0024-4066}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1093/biolinnean/blab130}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration%20Cerda-Company%20et%20al%20Vision%202021.JPG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration%20Cerda-Company%20et%20al%20Vision%202021.JPG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration%20Cerda-Company%20et%20al%20Vision%202021.JPG-1400.webp"></source> <img src="/assets/img/publication_preview/illustration%20Cerda-Company%20et%20al%20Vision%202021.JPG" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration Cerda-Company et al Vision 2021.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="vision5030037" class="col-sm-8"> <div class="title">Chromatic Induction in Migraine</div> <div class="author"> Xim Cerda-Company, <em>Olivier Penacchio</em>, and Xavier Otazu</div> <div class="periodical"> <em>Vision</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.mdpi.com/2411-5150/5/3/37/htm" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Chromatic%20Induction%20in%20Migraine%20Cerda-Company%20Penacchio%20Otazu%20Vision%202021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.3390/vision5030037" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.3390/vision5030037" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>The human visual system is not a colorimeter. The perceived colour of a region does not only depend on its colour spectrum, but also on the colour spectra and geometric arrangement of neighbouring regions, a phenomenon called chromatic induction. Chromatic induction is thought to be driven by lateral interactions: the activity of a central neuron is modified by stimuli outside its classical receptive field through excitatory–inhibitory mechanisms. As there is growing evidence of an excitation/inhibition imbalance in migraine, we compared chromatic induction in migraine and control groups. As hypothesised, we found a difference in the strength of induction between the two groups, with stronger induction effects in migraine. On the other hand, given the increased prevalence of visual phenomena in migraine with aura, we also hypothesised that the difference between migraine and control would be more important in migraine with aura than in migraine without aura. Our experiments did not support this hypothesis. Taken together, our results suggest a link between excitation/inhibition imbalance and increased induction effects.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">vision5030037</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cerda-Company, Xim and Penacchio, Olivier and Otazu, Xavier}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Chromatic Induction in Migraine}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Vision}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">article-number</span> <span class="p">=</span> <span class="s">{37}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3390/vision5030037}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2411-5150}</span><span class="p">,</span>
  <span class="na">pubmedid</span> <span class="p">=</span> <span class="s">{34449758}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.3390/vision5030037}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration%20Halpin%20et%20al%20Scientific%20Report%202020-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration%20Halpin%20et%20al%20Scientific%20Report%202020-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration%20Halpin%20et%20al%20Scientific%20Report%202020-1400.webp"></source> <img src="/assets/img/publication_preview/illustration%20Halpin%20et%20al%20Scientific%20Report%202020.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration Halpin et al Scientific Report 2020.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="WOS:000560461000024" class="col-sm-8"> <div class="title">Pattern contrast influences wariness in naive predators towards aposematic patterns</div> <div class="author"> Christina G. Halpin*, <em>Olivier Penacchio*</em>, P. George Lovell, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Innes C. Cuthill, Julie M. Harris, John Skelhorn, Candy Rowe' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>Scientific Reports</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.nature.com/articles/s41598-020-65754-y" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/aposematism%20defensive%20coloration%20pattern%20Pattern%20contrast%20influences%20wariness%20in%20naive%20predators%20Halpin%20Penacchio%20Rowe%20SciRep%202020.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1038/s41598-020-65754-y" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1038/s41598-020-65754-y" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>An apparent and common feature of aposematic patterns is that they contain a high level of achromatic (luminance) contrast, for example, many warning signals combine black spots and stripes with a lighter colour such as yellow. However, the potential importance of achromatic contrast, as distinct from colour contrast, in reducing predation has been largely overlooked. Here, using domestic chicks as a model predator, we manipulated the degree of achromatic contrast in warning patterns to test if high luminance contrast in aposematic signals is important for deterring naive predators. We found that the chicks were less likely to approach and eat prey with high contrast compared to low contrast patterns. These findings suggest that aposematic prey patterns with a high luminance contrast can benefit from increased survival through eliciting unlearned biases in naive avian predators. Our work also highlights the importance of considering luminance contrast in future work investigating why aposematic patterns take the particular forms that they do.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WOS:000560461000024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Halpin*, Christina G. and Penacchio*, Olivier and Lovell, P. George and Cuthill, Innes C. and Harris, Julie M. and Skelhorn, John and Rowe, Candy}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Pattern contrast influences wariness in naive predators towards
     aposematic patterns}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Scientific Reports}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">article-numer</span> <span class="p">=</span> <span class="s">{9246}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1038/s41598-020-65754-y}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2045-2322}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1038/s41598-020-65754-y}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="year">2019</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration%20Ruta%20et%20al%20Arch.Sci.Rev.%202019.JPG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration%20Ruta%20et%20al%20Arch.Sci.Rev.%202019.JPG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration%20Ruta%20et%20al%20Arch.Sci.Rev.%202019.JPG-1400.webp"></source> <img src="/assets/img/publication_preview/illustration%20Ruta%20et%20al%20Arch.Sci.Rev.%202019.JPG" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration Ruta et al Arch.Sci.Rev. 2019.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="WOS:000471331800008" class="col-sm-8"> <div class="title">A comparison between preference judgments of curvature and sharpness in architectural façades</div> <div class="author"> <a href="https://risweb.st-andrews.ac.uk/portal/en/persons/nicole-ruta(d0f51f88-dae2-4cc3-8436-51312f6ad7fc).html" rel="external nofollow noopener" target="_blank">Nicole Ruta</a>, Stefano Mastandrea, <em>Olivier Penacchio</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Stefania Lamaddalena, Giuseppe Bove' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Architectural Science Review</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.tandfonline.com/doi/abs/10.1080/00038628.2018.1558393?journalCode=tasr20" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/A%20comparison%20between%20preference%20judgments%20of%20curvature%20and%20sharpness%20in%20architectural%20fa%C3%A7ades%20Ruta%20et%20al%20Arch.Sci.Rev.%202019.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1080/00038628.2018.1558393" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1080/00038628.2018.1558393" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Can curvature drive preference, perceived familiarity, complexity, stability and approachability for architectural facades? In this study, we generated four versions of the same reference building, varying only the amount of curvature introduced in the facade. Participants’ judgments were measured using three experimental methodologies. Multidimensional scaling on forced choices showed that the curved facade was the most preferred. Multidimensional unfolding on ranking task showed that the majority of participants expressed higher preferences for the curved facade compared to the sharp-angled and rectilinear ones. Ratings on different psychological variables provided supporting evidence for curvature significantly influencing liking and approachability judgments. Results from image analyses -using a dynamical model of the visual cortex and a model that characterizes discomfort in terms of adherence to the statistics of natural images - matched behavioural data. We discuss the implications of the findings on our understanding of human preferences, which are intrinsically dynamic and influenced by context and experience.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WOS:000471331800008</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ruta, Nicole and Mastandrea, Stefano and Penacchio, Olivier and Lamaddalena, Stefania and Bove, Giuseppe}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A comparison between preference judgments of curvature and sharpness in
     architectural façades}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Architectural Science Review}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{62}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{171-181}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1080/00038628.2018.1558393}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0003-8628}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1080/00038628.2018.1558393}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="year">2018</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration%20countershading%20camouflage%20robust%20Penacchio%20et%20al%20RoySocOpenSci%202028.JPG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration%20countershading%20camouflage%20robust%20Penacchio%20et%20al%20RoySocOpenSci%202028.JPG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration%20countershading%20camouflage%20robust%20Penacchio%20et%20al%20RoySocOpenSci%202028.JPG-1400.webp"></source> <img src="/assets/img/publication_preview/illustration%20countershading%20camouflage%20robust%20Penacchio%20et%20al%20RoySocOpenSci%202028.JPG" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration countershading camouflage robust Penacchio et al RoySocOpenSci 2028.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="WOS:000426465700006" class="col-sm-8"> <div class="title">Is countershading camouflage robust to lighting change due to weather?</div> <div class="author"> <em>Olivier Penacchio</em>, P. George Lovell, and Julie M. Harris</div> <div class="periodical"> <em>Royal Society Open Science</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://royalsocietypublishing.org/doi/10.1098/rsos.170801" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Is%20countershading%20camouflage%20robust%20to%20lighting%20change%20Penacchio%20et%20al%20Roy.Soc.Open.Sci.%202018.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1098/rsos.170801" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1098/rsos.170801" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Countershading is a pattern of coloration thought to have evolved in order to implement camouflage. By adopting a pattern of coloration that makes the surface facing towards the sun darker and the surface facing away from the sun lighter, the overall amount of light reflected off an animal can be made more uniformly bright. Countershading could hence contribute to visual camouflage by increasing background matching or reducing cues to shape. However, the usefulness of countershading is constrained by a particular pattern delivering ‘optimal’ camouflage only for very specific lighting conditions. In this study, we test the robustness of countershading camouflage to lighting change due to weather, using human participants as a ‘generic’ predator. In a simulated three-dimensional environment, we constructed an array of simple leaf-shaped items and a single ellipsoidal target ‘prey’. We set these items in two light environments: strongly directional ‘sunny’ and more diffuse ‘cloudy’. The target object was given the optimal pattern of countershading for one of these two environment types or displayed a uniform pattern. Bymeasuring detection time and accuracy, we explored whether and how target detection depended on the match between the pattern of coloration on the target object and scene lighting. Detection times were longest when the countershading was appropriate to the illumination; incorrectly camouflaged targets were detected with a similar pattern of speed and accuracy to uniformly coloured targets. We conclude that structural changes in light environment, such as caused by differences in weather, do change the effectiveness of countershading camouflage.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WOS:000426465700006</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Penacchio, Olivier and Lovell, P. George and Harris, Julie M.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Is countershading camouflage robust to lighting change due to weather?}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Royal Society Open Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1098/rsos.170801}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2054-5703}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1098/rsos.170801}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="year">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration%20Le%20et%20al%20Land%20Urb%20Plan%202017.JPG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration%20Le%20et%20al%20Land%20Urb%20Plan%202017.JPG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration%20Le%20et%20al%20Land%20Urb%20Plan%202017.JPG-1400.webp"></source> <img src="/assets/img/publication_preview/illustration%20Le%20et%20al%20Land%20Urb%20Plan%202017.JPG" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration Le et al Land Urb Plan 2017.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="WOS:000394403300006" class="col-sm-8"> <div class="title">Discomfort from urban scenes: Metabolic consequences</div> <div class="author"> An T. D. Le, Jasmine Payne, Charlotte Clarke, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Murphy A. Kelly, Francesca Prudenziati, Elise Armsby, Olivier Penacchio, Arnold J. Wilkins' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>Landscape and Urban Planning</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S0169204616302699?via%3Dihub" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Discomfort%20from%20urban%20scenes%20Metabolic%20consequences%20Le%20et%20al%20Landscape%20and%20Urban%20Planning%202016.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1016/j.landurbplan.2016.12.003" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1016/j.landurbplan.2016.12.003" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Scenes from nature share in common certain statistical properties. Images with these properties can be processed efficiently by the human brain. Patterns with unnatural statistical properties are uncomfortable to look at, and are processed inefficiently, according to computational models of the visual cortex. Consistent with such putative computational inefficiency, uncomfortable images have been demonstrated to elicit a large haemodynamic response in the visual cortex, particularly so in individuals who are predisposed to discomfort. In a succession of five small-scale studies, we show that these considerations may be important in the design of the modern urban environment. In two studies we show that images from the urban environment are uncomfortable to the extent that their statistical properties depart from those of scenes from nature. In a third study we measure the haemodynamic response to images of buildings computed as having unnatural or natural statistical properties, and show that in posterior brain regions the images with unnatural statistical properties (often judged uncomfortable) elicit a haemodynamic response that is larger than for images with more natural properties. In two further studies we show that judgments of discomfort from real scenes (both shrubbery and buildings) are similar to those from images of the scenes. We conclude that the unnatural scenes in the modern urban environment are sometimes uncomfortable and place excessive demands on the neural computation involved in vision, with consequences for brain metabolism, and possibly also for health. (C) 2016 Elsevier B.V. All rights reserved.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WOS:000394403300006</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Le, An T. D. and Payne, Jasmine and Clarke, Charlotte and Kelly, Murphy A. and Prudenziati, Francesca and Armsby, Elise and Penacchio, Olivier and Wilkins, Arnold J.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Discomfort from urban scenes: Metabolic consequences}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Landscape and Urban Planning}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{160}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{61-68}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.landurbplan.2016.12.003}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0169-2046}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.landurbplan.2016.12.003}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Scientific%20Report%202017.JPG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Scientific%20Report%202017.JPG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Scientific%20Report%202017.JPG-1400.webp"></source> <img src="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Scientific%20Report%202017.JPG" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration Penacchio et al Scientific Report 2017.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="WOS:000413357500038" class="col-sm-8"> <div class="title">Establishing the behavioural limits for countershaded camouflage</div> <div class="author"> <em>Olivier Penacchio</em>, Julie M. Harris, and P. George Lovell</div> <div class="periodical"> <em>Scientific Report</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.nature.com/articles/s41598-017-13914-y" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Establishing%20the%20behavioural%20limits%20for%20CS%20Penacchio%20et%20al%20Sci.Rep.%202017.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1038/s41598-017-13914-y" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1038/s41598-017-13914-y" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Countershading is a ubiquitous patterning of animals whereby the side that typically faces the highest illumination is darker. When tuned to specific lighting conditions and body orientation with respect to the light field, countershading minimizes the gradient of light the body reflects by counterbalancing shadowing due to illumination, and has therefore classically been thought of as an adaptation for visual camouflage. However, whether and how crypsis degrades when body orientation with respect to the light field is non-optimal has never been studied. We tested the behavioural limits on body orientation for countershading to deliver effective visual camouflage. We asked human participants to detect a countershaded target in a simulated three-dimensional environment. The target was optimally coloured for crypsis in a reference orientation and was displayed at different orientations. Search performance dramatically improved for deviations beyond 15 degrees. Detection time was significantly shorter and accuracy significantly higher than when the target orientation matched the countershading pattern. This work demonstrates the importance of maintaining body orientation appropriate for the displayed camouflage pattern, suggesting a possible selective pressure for animals to orient themselves appropriately to enhance crypsis.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WOS:000413357500038</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Penacchio, Olivier and Harris, Julie M. and Lovell, P. George}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Establishing the behavioural limits for countershaded camouflage}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Scientific Report}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1038/s41598-017-13914-y}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2045-2322}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1038/s41598-017-13914-y}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2016</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration%20Cuthill%20et%20al%20PNAS%202016.JPG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration%20Cuthill%20et%20al%20PNAS%202016.JPG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration%20Cuthill%20et%20al%20PNAS%202016.JPG-1400.webp"></source> <img src="/assets/img/publication_preview/illustration%20Cuthill%20et%20al%20PNAS%202016.JPG" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration Cuthill et al PNAS 2016.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="WOS:000388970100065" class="col-sm-8"> <div class="title">Optimizing countershading camouflage</div> <div class="author"> Innes C. Cuthill, N. Simon Sanghera, <em>Olivier Penacchio</em>, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Paul George Lovell, Graeme D. Ruxton, Julie M. Harris' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Proceedings of the National Academy of Sciences of the United States of America</em>, 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.pnas.org/doi/full/10.1073/pnas.1611589113" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Optimizing%20countershading%20camouflage%20Cuthill%20et%20al%20PNAS%202016.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1073/pnas.1611589113" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1073/pnas.1611589113" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Countershading, the widespread tendency of animals to be darker on the side that receives strongest illumination, has classically been explained as an adaptation for camouflage: obliterating cues to 3D shape and enhancing background matching. However, there have only been two quantitative tests of whether the patterns observed in different species match the optimal shading to obliterate 3D cues, and no tests of whether optimal countershading actually improves concealment or survival. We use a mathematical model of the light field to predict the optimal countershading for concealment that is specific to the light environment and then test this prediction with correspondingly patterned model “caterpillars” exposed to avian predation in the field. We show that the optimal countershading is strongly illumination-dependent. A relatively sharp transition in surface patterning from dark to light is only optimal under direct solar illumination; if there is diffuse illumination from cloudy skies or shade, the pattern provides no advantage over homogeneous background-matching coloration. Conversely, a smoother gradation between dark and light is optimal under cloudy skies or shade. The demonstration of these illumination-dependent effects of different countershading patterns on predation risk strongly supports the comparative evidence showing that the type of countershading varies with light environment.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WOS:000388970100065</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cuthill, Innes C. and Sanghera, N. Simon and Penacchio, Olivier and Lovell, Paul George and Ruxton, Graeme D. and Harris, Julie M.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Optimizing countershading camouflage}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proceedings of the National Academy of Sciences of the United States of America}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{113}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{46}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{13093-13097}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1073/pnas.1611589113}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0027-8424}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1073/pnas.1611589113}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="year">2015</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20Wilkins%20Vision%20Research%202015.JPG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20Wilkins%20Vision%20Research%202015.JPG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20Wilkins%20Vision%20Research%202015.JPG-1400.webp"></source> <img src="/assets/img/publication_preview/illustration%20Penacchio%20Wilkins%20Vision%20Research%202015.JPG" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration Penacchio Wilkins Vision Research 2015.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="WOS:000350781100001" class="col-sm-8"> <div class="title">Visual discomfort and the spatial distribution of Fourier energy</div> <div class="author"> <em>Olivier Penacchio</em>, and Arnold J. Wilkins</div> <div class="periodical"> <em>Vision Research</em>, 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S0042698914003320?via%3Dihub" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/visual%20discomfort%20and%20the%20spatial%20distribution%20of%20Fourier%20energy%20Penacchio%20Wilkins%20VR%202015.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1016/j.visres.2014.12.013" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1016/j.visres.2014.12.013" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Quite independently of what they represent, some images provoke discomfort, and even headaches and seizures in susceptible individuals. The visual system has adapted to efficiently process the images it typically experiences, and in nature these images are usually scale-invariant. In this work, we sought to characterize the images responsible for discomfort in terms of their adherence to low-level statistical properties typically seen in natural scenes. It has been conventional to measure scale invariance in terms of the one-dimensional Fourier amplitude spectrum, by averaging amplitude over orientations in the Fourier domain. However, this loses information on the evenness with which information at various orientations is represented. We therefore fitted a two-dimensional surface (regular circular cone 1/f in logarithmic coordinates) to the two-dimensional amplitude spectrum. The extent to which the cone fitted the spectrum explained an average of 18% of the variance in judgments of discomfort from images including rural and urban scenes, works of non-representational art, images of buildings and animals, and images generated from randomly disposed discs of varying contrast and size. Weighting the spectrum prior to fitting the surface to allow for the spatial frequency tuning of contrast sensitivity explained an average of 27% of the variance. Adjusting the shape of the cone to take account of the generally greater energy in horizontal and vertical orientations improved the fit, but only slightly. Taken together, our findings show that a simple measure based on first principles of efficient coding and human visual sensitivity explained more variance than previously published algorithms. The algorithm has a low computational cost and we show that it can identify the images involved in cases that have reached the media because of complaints. We offer the algorithm as a tool for designers rather than as a simulation of the biological processes involved. (C) 2014 Elsevier Ltd. All rights reserved.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WOS:000350781100001</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Penacchio, Olivier and Wilkins, Arnold J.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Visual discomfort and the spatial distribution of Fourier energy}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Vision Research}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{108}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-7}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.visres.2014.12.013}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0042-6989}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.visres.2014.12.013}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Functional%20Ecology%202015.JPG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Functional%20Ecology%202015.JPG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Functional%20Ecology%202015.JPG-1400.webp"></source> <img src="/assets/img/publication_preview/illustration%20Penacchio%20et%20al%20Functional%20Ecology%202015.JPG" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration Penacchio et al Functional Ecology 2015.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="WOS:000361235200007" class="col-sm-8"> <div class="title">Orientation to the sun by animals and its interaction with crypsis</div> <div class="author"> <em>Olivier Penacchio</em>, Innes C. Cuthill, P. George Lovell, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Graeme D. Ruxton, Julie M. Harris' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Functional Ecology</em>, 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://besjournals.onlinelibrary.wiley.com/doi/10.1111/1365-2435.12481" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Orientation%20to%20the%20sun%20by%20animals%20and%20its%20interaction%20with%20crypsis%20Penacchio%20et%20al%20Functional%20Ecology%202015.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1111/1365-2435.12481" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1111/1365-2435.12481" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Orientation with respect to the sun has been observed in a wide range of species and has generally been interpreted in terms of thermoregulation and/or ultraviolet (UV) protection. For countershaded animals, orientation with respect to the sun may also result from the pressure to exploit the gradient of coloration optimally to enhance crypsis. Here, we use computational modelling to predict the optimal countershading pattern for an oriented body. We assess how camouflage performance declines as orientation varies using a computational model that incorporates realistic lighting environments. Once an optimal countershading pattern for crypsis has been chosen, we determine separately how UV protection/irradiation and solar thermal inflow fluctuate with orientation. We show that body orientations that could optimally use countershading to enhance crypsis are very similar to those that allow optimal solar heat inflow and UV protection. Our findings suggest that crypsis has been overlooked as a selective pressure on orientation and that new experiments should be designed to tease apart the respective roles of these different selective pressures. We propose potential experiments that could achieve this.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WOS:000361235200007</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Penacchio, Olivier and Cuthill, Innes C. and Lovell, P. George and Ruxton, Graeme D. and Harris, Julie M.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Orientation to the sun by animals and its interaction with crypsis}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Functional Ecology}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{29}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1165-1177}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1111/1365-2435.12481}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0269-8463}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1111/1365-2435.12481}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20at%20al%20American%20Naturalist%202015.JPG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20at%20al%20American%20Naturalist%202015.JPG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/illustration%20Penacchio%20at%20al%20American%20Naturalist%202015.JPG-1400.webp"></source> <img src="/assets/img/publication_preview/illustration%20Penacchio%20at%20al%20American%20Naturalist%202015.JPG" class="preview z-depth-1 rounded" width="auto" height="auto" alt="illustration Penacchio at al American Naturalist 2015.JPG" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="WOS:000362840100014" class="col-sm-8"> <div class="title">Three-Dimensional Camouflage: Exploiting Photons to Conceal Form</div> <div class="author"> <em>Olivier Penacchio</em>, P. George Lovell, Innes C. Cuthill, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Graeme D. Ruxton, Julie M. Harris' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>American Naturalist</em>, 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.journals.uchicago.edu/doi/10.1086/682570" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Three-dimensional%20camouflage%20Exploiting%20photons%20Penacchio%20et%20al%20Am.Nat.%202015.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1086/682570" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1086/682570" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Many animals have a gradation of body color, termed countershading, where the areas that are typically exposed to more light are darker. One hypothesis is that this patterning enhances visual camouflage by making the retinal image of the animal match that of the background, a fundamentally two-dimensional theory. More controversially, countershading may also obliterate cues to three-dimensional (3D) shape delivered by shading. Despite relying on distinct cognitive mechanisms, these two potential functions hitherto have been amalgamated in the literature. It has previously not been possible to validate either hypothesis empirically, because there has been no general theory of optimal countershading that allows quantitative predictions to be made about the many environmental parameters involved. Here we unpack the logical distinction between using countershading for background matching and using it to obliterate 3D shape. We use computational modeling to determine the optimal coloration for the camouflage of 3D shape. Our model of 3D concealment is derived from the physics of light and informed by perceptual psychology: we simulate a 3D world that incorporates naturalistic lighting environments. The model allows us to predict countershading coloration for terrestrial environments, for any body shape and a wide range of ecologically relevant parameters. The approach can be generalized to any light distribution, including those underwater.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WOS:000362840100014</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Penacchio, Olivier and Lovell, P. George and Cuthill, Innes C. and Ruxton, Graeme D. and Harris, Julie M.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Three-Dimensional Camouflage: Exploiting Photons to Conceal Form}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{American Naturalist}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{186}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{553-563}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1086/682570}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0003-0147}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1086/682570}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2013</h2> <ol class="bibliography"></ol> </div> <p>* shared first authorship</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Olivier Penacchio. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>